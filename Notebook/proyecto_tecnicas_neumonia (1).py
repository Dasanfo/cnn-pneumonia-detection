# -*- coding: utf-8 -*-
"""PROYECTO_TECNICAS_NEUMONIA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-xbGABrXWV_GuAlKFoRKZ9xyvHIBakuG

# Cargar imagenes
"""

import os
import shutil
import cv2
import numpy as np
import matplotlib.pyplot as plt
import keras
from random import randint
from keras.layers import Dense
from keras.models import Sequential
from keras.layers import Conv2D,MaxPooling2D,Flatten,Dropout

import kagglehub

# Download latest version
path = kagglehub.dataset_download("tawsifurrahman/covid19-radiography-database")

print("Path to dataset files:", path)

direccion = "/root/.cache/kagglehub/datasets/tawsifurrahman/covid19-radiography-database/versions/5"
for folder in os.listdir(direccion):
    subfolder_path = os.path.join(direccion, folder)
    if os.path.isdir(subfolder_path):
        for sub_folder in os.listdir(subfolder_path):
            sub_subfolder_path = os.path.join(subfolder_path, sub_folder)
            print(sub_subfolder_path)

for folder in os.listdir(direccion):
  subfolder_path = os.path.join(direccion,folder)
  if os.path.isdir(subfolder_path):
    for subfolder in os.listdir(subfolder_path):
      sub_subfolder_path = os.path.join(subfolder_path,subfolder)
      if os.path.isdir(sub_subfolder_path) and ("Normal" not in subfolder and "COVID" not in subfolder):
          # removemos los directorios que hacen referencia a la metadata
          shutil.rmtree(sub_subfolder_path)
      elif ".xlsx" in subfolder:
        # remover los xlsx
        os.remove(sub_subfolder_path)
      elif ".txt" in subfolder:
        os.remove(sub_subfolder_path)

for folder in os.listdir(direccion):
    subfolder_path = os.path.join(direccion, folder)
    if os.path.isdir(subfolder_path):
        print(f"\nContenido de '{folder}':", os.listdir(subfolder_path))

clases = ['Normal', 'COVID']
lista = []
lista_labels = []
for clase in clases:
  direccion_clase = os.path.join("/root/.cache/kagglehub/datasets/tawsifurrahman/covid19-radiography-database/versions/5/COVID-19_Radiography_Dataset",clase,"images")
  for subdir in os.listdir(direccion_clase):
    subdir_direccion = os.path.join(direccion_clase,subdir)
    imagen_numpy = cv2.imread(subdir_direccion,cv2.IMREAD_GRAYSCALE)
    imagen_resize = cv2.resize(imagen_numpy,(200,200))
    lista_labels.append(1) if clase == "COVID" else lista_labels.append(0)
    lista.append(imagen_resize)

x = np.array(lista)
y = np.array(lista_labels)

"""## 1. Análisis Exploratorio de Datos (20 %)

"""

unique_shapes = set(img.shape for img in x)
print("Dimensiones únicas de las imágenes:", unique_shapes) # se seteo las dimensiones de la imagen anteriormente en 200 aca solo verificamos que este bien

import numpy as np

# Buscar imágenes con valores anómalos (pixeles fuera del rango 0-255)
imagenes_corruptas = [i for i in range(len(x)) if x[i].min() < 0 or x[i].max() > 255]

# Ver si encontramos imágenes corruptas
if imagenes_corruptas:
    print(f"Se encontraron {len(imagenes_corruptas)} imágenes corruptas.")
else:
    print("No hay imágenes corruptas en el dataset.")

import matplotlib.pyplot as plt
import numpy as np

# Contar la cantidad de imágenes por clase
num_normal = np.sum(y == 0)
num_covid = np.sum(y == 1)

# Crear el gráfico de pastel
plt.figure(figsize=(6, 6))
plt.pie([num_normal, num_covid], labels=["Normal", "COVID"], autopct='%1.1f%%', colors=['blue', 'red'], startangle=90, wedgeprops={'edgecolor': 'black'})

# Configuración del gráfico
plt.title("Distribución de Clases en el Dataset")
plt.show()

# Evaluar balanceo del dataset
ratio = num_normal / num_covid
print(f"- Cantidad de imágenes - Normal: {num_normal}, COVID: {num_covid}")
print(f"- Ratio de clases (Normal/COVID): {ratio:.2f}")

if ratio < 0.8 or ratio > 1.2:
    print("- El dataset está desbalanceado, considera aplicar técnicas de balanceo.")
else:
    print("- El dataset está relativamente balanceado.")

"""# 2.Preprocesamiento de imagenes"""

indices_normal = np.where(y == 0)[0]  # Índices de imágenes "Normal"
indices_covid = np.where(y == 1)[0]   # Índices de imágenes "COVID"

# Seleccionar 6,000 imágenes aleatorias de la clase Normal
indices_normal_subsampled = np.random.choice(indices_normal, 6000, replace=False)

# Unir con todos los datos de COVID
indices_finales = np.concatenate([indices_normal_subsampled, indices_covid])

# Barajar
np.random.shuffle(indices_finales)

# Crear nuevo dataset balanceado parcialmente
x_balanced = x[indices_finales]
y_balanced = y[indices_finales]

print(f"Nuevo dataset tras submuestreo - Normal: {np.sum(y_balanced == 0)}, COVID: {np.sum(y_balanced == 1)}")

import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Aplicar Data Augmentation solo a imágenes COVID
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.05,
    zoom_range=0.1,
    brightness_range=[0.8, 1.2]
)

# Extraer imágenes de COVID
covid_images = x_balanced[y_balanced == 1]
num_extra = 6000 - len(covid_images)  # Cuántas imágenes extra necesitamos

x_augmented = []
y_augmented = []

for i in range(num_extra):
    img = covid_images[i % len(covid_images)]  # Seleccionar imagen de COVID (repite si es necesario)
    img = img.reshape((1,) + img.shape + (1,))  # Agregar dimensión extra
    aug_iter = datagen.flow(img, batch_size=1)  # Aplicar Data Augmentation
    x_augmented.append(next(aug_iter).reshape(img.shape[1:3]))  # ✅ USAMOS next()
    y_augmented.append(1)  # Etiqueta COVID

# Convertir listas en arrays de NumPy
x_augmented = np.array(x_augmented)
y_augmented = np.array(y_augmented)

# Unir datos originales con los aumentados
x_balanced = np.concatenate([x_balanced, x_augmented], axis=0)
y_balanced = np.concatenate([y_balanced, y_augmented], axis=0)

# Mezclar nuevamente
indices = np.random.permutation(len(x_balanced))
x_balanced = x_balanced[indices]
y_balanced = y_balanced[indices]

print(f"Dataset final balanceado - Normal: {np.sum(y_balanced == 0)}, COVID: {np.sum(y_balanced == 1)}")

#Necesitamos aleatorizar el orden del conjunto de datos para despues dividir en test y train
indices = np.random.permutation(len(x_balanced))

# Randomizamos el array
x_shuffled = x_balanced[indices]
y_shuffled = y_balanced[indices]

x_shuffled.shape

y_shuffled.size

# División 80% - 20%
#Justificar en el informe porque se hizo esta division
split_idx = int(0.8 * len(x_shuffled))

#Entrenamiento
x_train, y_train = x_shuffled[:split_idx], y_shuffled[:split_idx]

#Prueba
x_test, y_test = x_shuffled[split_idx:], y_shuffled[split_idx:]

#Tamaños de los conjuntos
print("Tamaño de x_train:", x_train.shape)
print("Tamaño de y_train:", y_train.shape)
print("Tamaño de x_test:", x_test.shape)
print("Tamaño de y_test:", y_test.shape)

x_test_copia = x_test.copy()

num_classes = 2
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

#normalizamos las imagenes del dataset
x_train = x_train / 255.0
x_test = x_test / 255.0

x_train = x_train.reshape(-1, 200, 200, 1)
x_test = x_test.reshape(-1,200,200, 1)

"""Durante la carga de las imagenes dejamos las imagenes en escala de grises y definimos el tamaño de las imagenes.
Sin embargo, si es necesario para que el modelo aprenda bien podemos hacer data aumentacion de imagenes para que capte mejor los patrones

# Arquitectura red neuronal
"""

model = Sequential()
#Capa convolusional 1
model.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', input_shape = (200,200,1)))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
# capa convolusional 2
model.add(Conv2D(filters = 16, kernel_size = (5,5), activation ='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

# capa convolusional
model.add(Conv2D(filters = 32, kernel_size = (5,5), activation ='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))


# fully connected
model.add(Flatten())
model.add(Dense(200, activation = "relu"))
model.add(Dropout(0.4))
model.add(Dense(2, activation = "sigmoid"))

model.summary()

"""# Entrenamiento"""

optimizer = keras.optimizers.SGD(learning_rate=0.01)

model.compile(optimizer="sgd", loss='categorical_crossentropy', metrics=['accuracy'])

#model.compile(optimizer="sgd", loss='categorical_crossentropy', metrics=['accuracy',metrics.Precision(name='precision')])

history = model.fit(x_train, y_train, batch_size=8, epochs=12, verbose=2, validation_split=0.1)

loss, accuracy  = model.evaluate(x_test, y_test, verbose=1)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training', 'validation'], loc='best')
plt.show()

print(f'Test loss: {loss:.3}')
print(f'Test accuracy: {accuracy:.3}')

"""# Pruebas y predicciones del modelo"""

test_img = randint(0,x_test_copia.shape[0])
X_test_img = x_test_copia[test_img]
plt.imshow(X_test_img, cmap='Greys')
plt.show()
X_test_img = X_test_img.reshape(1, 200, 200, 1)
prediction = model.predict(X_test_img)
print('Condicion predicha del paciente: ', prediction.argmax())
print('Condicion real del paciente: ', y_test[test_img])